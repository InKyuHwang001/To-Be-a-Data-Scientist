# 기초이론

머신러닝, Neural Network, Loss function,Activation Function, 경사하강법

---

## 머신러닝: 그냥 수학계산

머신러닝으로 풀 수 있는 문제는

1. 음성을 자동으로 자막으로 생성해주기 
2. 비슷한 영화끼리 분류해주는 영화 추천서비스 만들기
3. 사진속에 나오는 사물이 자동차인지 보행자인지 맞추기 

데이터의 **규칙성**만 있다면 컴퓨터에 학습시켜 스스로 판단한다.



**수능점수= 6모점수xA+9모점수xB**

A,B라는 미지수 점수 추론하면 됨

컴퓨터가 A와B를 추론하여 수능점수를 추론하게 함



A와 B값을 추론하는 기준이 중요

수험생들의 6월, 9월, 수능점수 데이터를 가져오기

내 모델의 예측결과 vs 실제 수능점수를 비교해서 오차가 최소화되는 A와 B값을 찾기

A,B를 **가중치**(weight) 라고 함



## 신경망

**수능점수= 6모점수xA+9모점수xB**라고 하기엔 너무 단순함

인간처럼 기계도 생각 하게 해보면 어떨까?

중간에 레이어(층)을 하나 추가 하면  어떨까?

사람처럼 생각을 잠깐 저장한 후에 예측을 해낼수 있겠네.



중간레이어는 은닉층(hidden layer)라고 불림

그냥 사람 뇌 신경망처럼 해보니까 잘나와서 많이 쓰이게 됨.

### 사람 얼굴 인식 예

은닉층에서 얼굴의 윗부분을 한곳에 모으고 하관을 한곳에 모은 후 사람의 얼굴일 확률을 구함

## Loss function(손실함수)

![img](https://codingapple.com/wp-content/uploads/2020/10/%EC%BA%A1%EC%B2%981.png)

동그라미: node

h1(node)는 가중치를 곱해 연결된 모든 이전 노드들을 다 더함

**손실함수(=cost function이라고도 함)**= 오차를 구하는 수식

## Activation Function

- 은닉층의 유무는 결과에 영향을 주지 못한다.

이를 해결하기 위해 은닉층 h1에서 값을 변형시키는 함수가 **활성함수(Activation Function)**이다.



활성함수(Activation Function) 예

1. sigmoid
2. hyperbolic tangent
3. softmax
4. Rectified Linear Units
   - 양수값만 그대로 오고 나머지는 0



활성함수 없이 예측: 선형적이고 단순한 예측

활성함수 포함한 예측: 비 선형적이고 복잡한 예측가능

## 경사 하강법

**경사하강법**이란	

- x축을 w로 하고 y축을 총손실로 할때 **w의 증감을 판단하는 기준**
- w값에서 현재의 w값에서의 접선의 기울기를 빼셈
- 단 기울기에 learning rate를 곱하여 빼야 한다.
  - 안그러면 최솟값이 아닌 곳에서 멈출 수 있기 때문
  - **learning rate optimizer** :learning rate를 상수가 아니라 가변적으로 하는것
    - Momentum : 가속도를 유지
    - AdaGrad 
    - Adam 등등

**딥러닝이란** 최적의 w값을 찾는 과정이다.



