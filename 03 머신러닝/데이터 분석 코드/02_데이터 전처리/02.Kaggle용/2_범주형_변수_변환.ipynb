{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# train_x는 학습 데이터, train_y는 목적 변수, test_x는 테스트 데이터\n",
        "# pandas의 DataFrame, Series의 자료형 사용(numpy의 array로 값을 저장하기도 함.)\n",
        "\n",
        "train = pd.read_csv('../input/sample-data/train.csv')\n",
        "train_x = train.drop(['target'], axis=1)\n",
        "train_y = train['target']\n",
        "test_x = pd.read_csv('../input/sample-data/test.csv')\n",
        "\n",
        "\n",
        "# 설명용으로 학습 데이터와 테스트 데이터의 원래 상태를 복제해 두기\n",
        "train_x_saved = train_x.copy()\n",
        "test_x_saved = test_x.copy()\n",
        "\n",
        "\n",
        "# 학습 데이터와 테스트 데이터를 반환하는 함수\n",
        "def load_data():\n",
        "    train_x, test_x = train_x_saved.copy(), test_x_saved.copy()\n",
        "    return train_x, test_x\n",
        "\n",
        "# 변환할 수치 변수를 목록에 저장\n",
        "cat_cols = ['sex', 'product', 'medical_info_b2', 'medical_info_b3']"
      ],
      "metadata": {
        "id": "lL-8lLzlPQFy"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1.원핫인코딩"
      ],
      "metadata": {
        "id": "7Y4X_iPaPDuy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 특징의 개수가 범주형 변수의 레벻 개수에 따라 증가한다.\n",
        "- 레벨의 종류가 많을 때는 계산의 시간이 급증한다.\n",
        "- 해결방법\n",
        "  1. 다른 인코딩 방법 사용\n",
        "  2. 임의의 규칙을 활용 그룹화 범주수 줄이기\n",
        "  3. 비도가 낮은 범주를 모두 '기타 범주'로 줄이기"
      ],
      "metadata": {
        "id": "jP1zJX-CQHIM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## get_dummies"
      ],
      "metadata": {
        "id": "ZtGMkOkYPqpP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fZ2A_tJ6O-FJ"
      },
      "outputs": [],
      "source": [
        "train_x, test_x = load_data()\n",
        "# -----------------------------------\n",
        "\n",
        "# 학습 데이터와 테스트 데이터를 결합하여 get_dummies를 통한 원-핫 인코딩을 수행\n",
        "all_x = pd.concat([train_x, test_x])\n",
        "all_x = pd.get_dummies(all_x, columns=cat_cols)\n",
        "\n",
        "# 학습 데이터와 테스트 데이터의 재분할\n",
        "train_x = all_x.iloc[:train_x.shape[0], :].reset_index(drop=True)\n",
        "test_x = all_x.iloc[train_x.shape[0]:, :].reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## OneHotEncoder"
      ],
      "metadata": {
        "id": "zXJSZKY_PcJL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_x, test_x = load_data()\n",
        "# -----------------------------------\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "# OneHotEncoder로 인코딩\n",
        "ohe = OneHotEncoder(sparse=False, categories='auto')\n",
        "ohe.fit(train_x[cat_cols])\n",
        "\n",
        "# 가변수의 컬럼명 생성\n",
        "columns = []\n",
        "for i, c in enumerate(cat_cols):\n",
        "    columns += [f'{c}_{v}' for v in ohe.categories_[i]]\n",
        "\n",
        "# 생성된 가변수를 데이터 프레임으로 변환\n",
        "dummy_vals_train = pd.DataFrame(ohe.transform(train_x[cat_cols]), columns=columns)\n",
        "dummy_vals_test = pd.DataFrame(ohe.transform(test_x[cat_cols]), columns=columns)\n",
        "\n",
        "# 나머지 변수와의 결합\n",
        "train_x = pd.concat([train_x.drop(cat_cols, axis=1), dummy_vals_train], axis=1)\n",
        "test_x = pd.concat([test_x.drop(cat_cols, axis=1), dummy_vals_test], axis=1)"
      ],
      "metadata": {
        "id": "if27RUQ9PcdC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2.라벨인코딩"
      ],
      "metadata": {
        "id": "trNT6sB2PvQG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_x, test_x = load_data()\n",
        "# -----------------------------------\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# 범주형 변수를 for문 루프하여 반복적으로 레이블 인코딩 수행\n",
        "for c in cat_cols:\n",
        "    # 학습 데이터에 근거하여 정의한 후에 데이터 변환\n",
        "    le = LabelEncoder()\n",
        "    le.fit(train_x[c])\n",
        "    train_x[c] = le.transform(train_x[c])\n",
        "    test_x[c] = le.transform(test_x[c])"
      ],
      "metadata": {
        "id": "1LAWa8DeUX6a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3.특징 해싱"
      ],
      "metadata": {
        "id": "2lagHLMAUeMR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "정의: 특벨 수를 줄이는 방법\n",
        "변환 후의 특징 수를 정해두고, 해시 함수를 이용하여 레벨별로 플래그를 표시할 위치를 설정"
      ],
      "metadata": {
        "id": "oLto8GlMUt-u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_x, test_x = load_data()\n",
        "# -----------------------------------\n",
        "from sklearn.feature_extraction import FeatureHasher\n",
        "\n",
        "# 범주형 변수를 반복적으로 특징 해싱 처리\n",
        "for c in cat_cols:\n",
        "    # FeatureHasher의 사용법은 다른 encoder와 조금 달라짐\n",
        "    fh = FeatureHasher(n_features=5, input_type='string')\n",
        "\n",
        "    # 변수를 문자열로 변환한 후 FeatureHasher 적용\n",
        "    hash_train = fh.transform(train_x[[c]].astype(str).values)\n",
        "    hash_test = fh.transform(test_x[[c]].astype(str).values)\n",
        "\n",
        "    # 데이터 프레임으로 변환\n",
        "    hash_train = pd.DataFrame(hash_train.todense(), columns=[f'{c}_{i}' for i in range(5)])\n",
        "    hash_test = pd.DataFrame(hash_test.todense(), columns=[f'{c}_{i}' for i in range(5)])\n",
        "\n",
        "    # 원래의 데이터 프레임과 결합\n",
        "    train_x = pd.concat([train_x, hash_train], axis=1)\n",
        "    test_x = pd.concat([test_x, hash_test], axis=1)\n",
        "\n",
        "# 원래의 범주형 변수 삭제\n",
        "train_x.drop(cat_cols, axis=1, inplace=True)\n",
        "test_x.drop(cat_cols, axis=1, inplace=True)"
      ],
      "metadata": {
        "id": "8nbWGxA4Ug5S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4.프리퀀시 인코딩"
      ],
      "metadata": {
        "id": "45Rzrzf9VOFM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 각 레벨의 출현 횟수 또는 출현 빈도로 볌주형 변수를 대체\n",
        "- **동률의 값**이 발생할 때도 있다. "
      ],
      "metadata": {
        "id": "jD0oddFhVTud"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_x, test_x = load_data()\n",
        "# -----------------------------------\n",
        "# for문을 이용한 변수를 반복하여 프리퀀시 인코딩 수행\n",
        "for c in cat_cols:\n",
        "    freq = train_x[c].value_counts()\n",
        "    # 카테고리 출현 횟수로 치환\n",
        "    train_x[c] = train_x[c].map(freq)\n",
        "    test_x[c] = test_x[c].map(freq)"
      ],
      "metadata": {
        "id": "j1jbe69xVRMu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5.타깃 인코딩"
      ],
      "metadata": {
        "id": "Y_4vJfoBVq6K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 목적변수를 이용하여 범주형 변수를 수치형 변환하는 방법\n",
        "- Target Encoding은 카테고리마다 목적 변수의 평균을 할당\n",
        "  - 출처: https://engineer-mole.tistory.com/197 [매일 꾸준히, 더 깊이:티스토리]"
      ],
      "metadata": {
        "id": "TgpOYN4bVuAL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_x, test_x = load_data()\n",
        "# -----------------------------------\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "# for문을 이용한 변수를 반복하여 타깃 인코딩 수행\n",
        "for c in cat_cols:\n",
        "    # 학습 데이터 전체에서 각 범주별 타깃 평균을 계산\n",
        "    data_tmp = pd.DataFrame({c: train_x[c], 'target': train_y})\n",
        "    target_mean = data_tmp.groupby(c)['target'].mean()\n",
        "\n",
        "    # 테스트 데이터의 카테고리 변경\n",
        "    test_x[c] = test_x[c].map(target_mean)\n",
        "\n",
        "    # 학습 데이터 변환 후 값을 저장하는 배열을 준비\n",
        "    tmp = np.repeat(np.nan, train_x.shape[0])\n",
        "\n",
        "    # 학습 데이터 분할\n",
        "    kf = KFold(n_splits=4, shuffle=True, random_state=72)\n",
        "    for idx_1, idx_2 in kf.split(train_x):\n",
        "        # 아웃 오브 폴드로 각 범주형 목적변수 평균 계산\n",
        "        target_mean = data_tmp.iloc[idx_1].groupby(c)['target'].mean()\n",
        "        # 변환 후의 값을 날짜 배열에 저장\n",
        "        tmp[idx_2] = train_x[c].iloc[idx_2].map(target_mean)\n",
        "\n",
        "    # 변환 후의 데이터로 원래의 변수를 변경\n",
        "    train_x[c] = tmp"
      ],
      "metadata": {
        "id": "9bIX6c8yVtjx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# target encoding - 교차 검증의 fold와 target encoding의 fold 분할을 맞추는 경우\n",
        "# -----------------------------------\n",
        "# 데이터 읽어오기\n",
        "train_x, test_x = load_data()\n",
        "# -----------------------------------\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "# 교차 검증의 폴드를 정의\n",
        "kf = KFold(n_splits=4, shuffle=True, random_state=71)\n",
        "\n",
        "# 변수를 루프하여 타깃 인코딩 수행\n",
        "for c in cat_cols:\n",
        "\n",
        "    # 타깃을 추가\n",
        "    data_tmp = pd.DataFrame({c: train_x[c], 'target': train_y})\n",
        "    # 변환 후 값을 저장하는 배열을 준비\n",
        "    tmp = np.repeat(np.nan, train_x.shape[0])\n",
        "\n",
        "    # 학습 데이터에서 검증 데이터를 나누기\n",
        "    for i, (tr_idx, va_idx) in enumerate(kf.split(train_x)):\n",
        "        # 학습 데이터에 대해 각 범주별 목적변수 평균 계산\n",
        "        target_mean = data_tmp.iloc[tr_idx].groupby(c)['target'].mean()\n",
        "        # 검증 데이터에 대해 변환 후 값을 날짜 배열에 저장\n",
        "        tmp[va_idx] = train_x[c].iloc[va_idx].map(target_mean)\n",
        "\n",
        "    # 변환 후의 데이터로 원래의 변수를 변경\n",
        "    train_x[c] = tmp"
      ],
      "metadata": {
        "id": "1rhMQ5HiXyPl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6.임베딩\n"
      ],
      "metadata": {
        "id": "2A9Uhi6EX3S4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "자연어 처리에서 단어나, 범주형 데변우와 같은 이산적인 표현을 실수 벡테로 변환하는 방법"
      ],
      "metadata": {
        "id": "bnZHCnTUX50w"
      }
    }
  ]
}