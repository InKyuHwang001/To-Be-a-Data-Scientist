{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "3장 숫자 세계로 떠난 자연어.ipynb",
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "aa178a5b9c154d4baac3686d740e83ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_769b5d2442ec4d44b5294b9c6101893d",
              "IPY_MODEL_e7dc6c48fed84690a806291e29a74704",
              "IPY_MODEL_1235482fd89e481cbbe59cf1f0ddd667"
            ],
            "layout": "IPY_MODEL_742e06c227ec49c48ee90d2ea4887ff2"
          }
        },
        "769b5d2442ec4d44b5294b9c6101893d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0e2b39ea07184c50b41f486a36d14422",
            "placeholder": "​",
            "style": "IPY_MODEL_43cc958b8b87442d84183bd8a5abc666",
            "value": "Downloading: 100%"
          }
        },
        "e7dc6c48fed84690a806291e29a74704": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5ff0ee291c8a4b9c9df24b8b5b863f42",
            "max": 438218004,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_04af07c986204789bd33c6437b4884b6",
            "value": 438218004
          }
        },
        "1235482fd89e481cbbe59cf1f0ddd667": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_206bf0bf0bdb4668a7b30d76207b36cc",
            "placeholder": "​",
            "style": "IPY_MODEL_f54057ce3c3546e199a2e834eb914b01",
            "value": " 438M/438M [00:06&lt;00:00, 67.1MB/s]"
          }
        },
        "742e06c227ec49c48ee90d2ea4887ff2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0e2b39ea07184c50b41f486a36d14422": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "43cc958b8b87442d84183bd8a5abc666": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5ff0ee291c8a4b9c9df24b8b5b863f42": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "04af07c986204789bd33c6437b4884b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "206bf0bf0bdb4668a7b30d76207b36cc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f54057ce3c3546e199a2e834eb914b01": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## 미리 학습된 언어 모델"
      ],
      "metadata": {
        "id": "bioepwkt2Pd9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 언어 모델\n",
        "언어 모델은 **단어 시퀀스에 확률을 부여**하는 모델이다.\n",
        "- 풀어서 단어 시퀀스를 입력받아 해당 시퀀스가 얼마나 그럴듯한지 확률을 출력하는 모델\n",
        "\n",
        "**결합확률**과 **조건부확률**로 나타낸다면\n",
        "\n",
        "**전체 단어 시퀀스**가 나타날 확률은 **이전 단어들이 주어졌을 때** 다음 단어가 **등장할 확률의 연쇄**이다. \n",
        "\n",
        "언어 모델은 **이전 단어들이 주어졌을 깨 다음 단어가 나타날 확률을 부여**하는 모델이다.\n",
        "\n",
        "\n",
        "\n",
        "**순방향 언어 모델**\n",
        "\n",
        "이전 단어들(컨텍스트)가 주어졌을 때 다음 단어 맞히기\n",
        "GPT,ELMo\n",
        "\n",
        "\n",
        "\n",
        "**역방향 언어 모델**\n",
        "\n",
        "문장을 뒤에서 앞으로 계산하는 모델\n",
        "- ELMo: 순방향과 역방향 모두 사용\n",
        "\n",
        "### 넓은 의미의 언어 모델\n",
        "  P(w|context)\n",
        "\n",
        "컨텍스트가 전제된 상태에서 특정 단어가 나타날 조건부 확률\n",
        "\n",
        "**마스크 언어 모델**\n",
        "\n",
        "학습 대상 문장에 빈칸을 만들어 놓고 해당 빈칸에 올 단어로 적절한 단어가 무엇일지 분류하는 과정\n",
        "- BERT\n",
        "\n",
        "문장 전체의 맥락을 참고할 수 있다는 장점(**양방향 성질**)\n",
        "\n",
        "**스킵-그램 모델**\n",
        "\n",
        "어떤 단어 **앞뒤에 특정 범위를 정해** 두고 이 **범위 내에서 어떤 단어**들이 올지 분류하는 과정으로 학습\n",
        "\n",
        "컨텍스트로 설정한 단어 주변에 어떤 단어들이 분포해 있는지를 학습한다\n",
        "- Word2Vec\n",
        "\n",
        "### 언어모델의 유용성"
      ],
      "metadata": {
        "id": "OyWfX6pG2-E9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 트랜스포모 살펴보기\n"
      ],
      "metadata": {
        "id": "DJfBinng2PXF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "트렌스 포머는 시퀀스-투-시퀀스모델\n",
        "\n",
        "### 시퀀스-투-시퀀스\n",
        "시퀀스-투-시퀀스란 **특정 속성을 지닌 시퀀스**를 **다른 속성의 시퀀스로 변환**하는 작업\n",
        "\n",
        "시퀀스: 단어 같은 무언가의 나열 \n",
        "### 인코더와 디코더\n",
        "트랜스포머는 시퀀스-투-시퀀스에 특화된 모델\n",
        "- 사용예: 기온의 시퀀스-> 태풍 발생 여부의 시퀀스\n",
        "\n",
        "인코더와 디코더로 구성\n",
        "\n",
        "**인코더**\n",
        "\n",
        "소스 시퀀스 정보를 압축(인코딩)\n",
        "\n",
        "**디코더**\n",
        "\n",
        "시퀀스 정보를 받아서 타깃 시퀀스를 생성(디코딩)\n"
      ],
      "metadata": {
        "id": "7qS6lE7q7WMJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 모델 학습과 인퍼런스\n",
        "\n",
        "트랜스포머는 인코더와 디코ㅔ 입력이 주어졌을 때 정답에 해당하는 단어의 확률 값을 높이는 방식으로 학습\n",
        "\n",
        "세부 예시는 책 참조(74~76)\n",
        "\n",
        "### 트렌스포머 블록\n",
        "**블록(레이어)** 인(디)코더에 반복되는 요소를 나타낸 것\n",
        "\n",
        "트렌스포어의 인코더는 블록이 수십 개 쌓아 구성\n",
        "\n",
        "인코더 블록: 멜티 헤드 어텐션, 피드포워드 뉴럴네트워크, 전자 연결 및 레이어 정규화 등 3가지로 구성\n",
        "\n",
        "디코더 블록: 마스크를 적용한 멀티 헤드 어텐션이 인코더와 다르고 인코더가 보내온 정보와 디코더 입력을 함께 이용해 멀티 헤드 어텐션을 수행할 모듈이 추가\n"
      ],
      "metadata": {
        "id": "xOtj4n1E9KV6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 셀프 어텐션\n",
        "멀티헤드 어텐션 = 셀프 어텐션\n",
        "트렌스포머의 경쟁력원천\n",
        "\n",
        "**어텐션**: \n",
        "- 시퀀스 입력에 수행하는 기계학습 방법\n",
        "- 중요한 요소에 집중하고 아닌 요소는 무시해 태스크 수행-> 성능 UP\n",
        "\n",
        "기계번역에 어텐션을 도입하면 **디코딩**에 도움이 되는 단어 위주로 **취사 선택**하여 번역 품질을 올림\n",
        "\n",
        "셀프 어텐션은 자신엥게 수행하는 어텐션 기법\n",
        "\n",
        "**합성곱 긴경망(CNN)**\n",
        "\n",
        "합성곱 필터를 이용하여 지역적인 특성을 잡아내는 모델\n",
        "\n",
        "CNN은 학성곱 필터 크기를 넘어서는 문맥은 읽어내기 어렵다는 단점\n",
        "\n",
        "**순환 신경망(RNN)**\n",
        "\n",
        "시퀀스 정보를 압축하는 데 강점\n",
        "\n",
        "But 마지막 단어에 집중하고 전반부 단어는 잊는 경향\n",
        "\n",
        "**특징 및 장점**\n",
        "\n",
        "어제 카페 갔었어 거기 사람 많더라\n",
        "\n",
        "거기는 카페와 갔었어에 크게 반영\n",
        "\n",
        "카페 역시 거기와 갔었어 크게 반영\n",
        "\n",
        "\n",
        "- 개별 단어와 전체 입력 시퀀스를 대상으로 어텐션 계산을 수행해 문맥 전체를 고려하므로 지역적인 문맥만 보는 CNN보다 강점\n",
        "- 모든 경우의 수를 고려하기(1대1로 바라보게 함) 때문에 길어져도 왜곡이 적음(RNN단점 극복)\n",
        "\n",
        "\n",
        "**계산**\n",
        "\n",
        "셀프 어텐션은 쿼리, 키, 밸류가 서로 영향을 주고 받으면서 문장의 의미를 계산한다.\n",
        "\n",
        "밸퓨 벡터들을 가중합하는 방식으로 계산"
      ],
      "metadata": {
        "id": "-NuMy5PzAGYL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 셀프 어텐션 동작 원리"
      ],
      "metadata": {
        "id": "oatB9KHT2PNU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "nDqtzzyuaCCu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 트랜스포머에 적용된 기술들"
      ],
      "metadata": {
        "id": "i8sTVjjD2PHe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 피드포워드 뉴럴 네트워크\n",
        "멀티 헤드 어텐션의 개별 출력 벡터가 입력이 됨\n",
        "\n",
        "입력층 출력층 은닉층으로 구성\n",
        "\n",
        "활성 함수는 **ReLu**임\n",
        "\n",
        "- ReLu:양수는 그대로 출력하고 음수는 0으로 치환해서 무시함\n",
        "\n",
        "**학습대상** \n",
        "\n",
        "가중치와 바이어스 for task(ex:기계학습)을 잘하는 방향\n"
      ],
      "metadata": {
        "id": "Sm0RDBtmFh3t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#피드포워드 뉴럴 네트워크 계산 예시\n",
        "import torch as to\n",
        "\n",
        "x=to.tensor([2,1]) #입력\n",
        "w1=to.tensor([[3,2,-4],[2,-3,1]])#입력층-은닉층 가중치\n",
        "b1=1#입력층-은닉층 바이어스\n",
        "w2=to.tensor([[-1,1],[1,2],[3,1]])#은닉층-출력층 가중치\n",
        "b2=-1#은닉층-출력층 바이어스\n",
        "\n",
        "h_preact=to.matmul(x,w1)+b1\n",
        "h=to.nn.functional.relu(h_preact)\n",
        "y=to.matmul(h, w2) + b2\n",
        "print(h_preact )\n",
        "print(h )\n",
        "print( y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ats_NmwZH0S-",
        "outputId": "1e2eba32-ab0e-4560-f224-e31a346783c3"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 9,  2, -6])\n",
            "tensor([9, 2, 0])\n",
            "tensor([-8, 12])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**잔차 연결**\n",
        "\n",
        "블록이나 레이어를 하나 건너뛰는 경로를 하나 두는 것(F(x)+x로 실현)\n",
        "\n",
        "모델이 다양한 관점에서 블록 걔산을 수행하게 된다.\n",
        "\n",
        "**레이어 정규화**\n",
        "\n",
        "미니 배치의 인스턴스별로 정규화를 수행하는 방법\n",
        "학습이 안정되고 속도가 빨라지는 효과\n"
      ],
      "metadata": {
        "id": "v2CvaqYFKhPP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#레이어 정규화 예시\n",
        "import torch\n",
        "input=torch.tensor([[1.0,2.0,3.0],[1,1,1]])\n",
        "m=torch.nn.LayerNorm(input.shape[-1])\n",
        "output=m(input)\n",
        "\n",
        "print(output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MLF_oI_gL6D7",
        "outputId": "76156683-7288-4d0b-ff47-f310da669f0d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-1.2247,  0.0000,  1.2247],\n",
            "        [ 0.0000,  0.0000,  0.0000]], grad_fn=<NativeLayerNormBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 모델 학습 기법\n",
        "\n",
        "**드롭아웃**\n",
        "\n",
        "**과적합을 방지**하고자 뉴런의 일부를 확률적으로 0으로 대치하여 계산에서 제외함"
      ],
      "metadata": {
        "id": "p5rVUVogM6v7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#드롭아웃\n",
        "import torch\n",
        "m=torch.nn.Dropout(p=0.2) #20%로 드롭 아웃 수행\n",
        "input=torch.randn(1,10)\n",
        "output=m(input)\n",
        "\n",
        "print(input)\n",
        "output\n",
        "\n",
        "#드롭아웃 결과 80%는 1.25배로 증가함\n",
        "#학습과정에만 적용됨"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gag7DXMgNeyv",
        "outputId": "8e13f59b-5fcc-4e5d-dfa1-506dc7db0bed"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.2999,  0.1314,  0.8110, -0.5142,  0.0260,  0.0054,  1.1157, -0.4485,\n",
            "          0.7833, -0.2591]])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.0000,  0.1642,  1.0137, -0.6428,  0.0325,  0.0068,  0.0000, -0.5606,\n",
              "          0.9791, -0.3238]])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**아담 옵티마이저**\n",
        "\n",
        "딥러닝 학습은 오차의 최소하는 방향으로 파라미터를 업데이트 과정\n",
        "- 오차를 **손실**\n",
        "- 오차를 최소화 하는 방향을 **그레이디언트**\n",
        "- 최소화 하는 과정을 **최적화**\n",
        "- **파라미터**: 모델 구성요소\n",
        "  - 남자 키 정규 본로라는 모델\n",
        "    - 평균키, 펴즌편차가 파라미터\n",
        "- **순전파**:모델을 처음에서 끝 방향으로 계산\n",
        "- **역전파**: 순전파의 역순으로 계산 \n",
        "\n",
        "**아담옵티마이저**: \n",
        "\n",
        "파라미터를 업데이트 할때의 보폭을 최적화 하는 도구 중 하나\n",
        "\n",
        "그레디언트는 관성을 가지고\n",
        "보폭은 안가본곳은 크게 가본곳은 작게"
      ],
      "metadata": {
        "id": "4VGhjLnfOiAi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#아담 옵티마이저\n",
        "from torch.optim import Adam\n",
        "optimizer=Adam(model.parameters(), lr=model.learning_rate)\n",
        "#learning_rate은 최초의 보폭"
      ],
      "metadata": {
        "id": "2gYkx1Z2Q7Pj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## BERT와 GPT 비교"
      ],
      "metadata": {
        "id": "Tx7xpG5S2PEu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### BERT와 GPT\n",
        "GPT\n",
        "- 일방향\n",
        "- 문장 생성\n",
        "\n",
        "BERT\n",
        "- 양방향 성격\n",
        "- 문장의 의미 추출\n",
        "\n",
        "### GPT 구조\n",
        "- 트랜스포머에서 인코더를 제외하고 디코더만 사용\n",
        "- 디코더에서도 인코더 정보를 받는 부분 없음\n",
        "\n",
        "### BERT 구조\n",
        "- 트랜스포머에서 인코더만 사용\n",
        "\n",
        "### 최근 트렌드\n",
        "- 모델 크기 증가 추세\n",
        "- 모델의 크기 줄이려는 노력"
      ],
      "metadata": {
        "id": "nU5WgiCiReHg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 단어/문장을 벡터로 변환하기"
      ],
      "metadata": {
        "id": "SaS--1ta2O_T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 파인튜닝\n",
        "다운스트림 데이터로 업데이트하는 과정\n",
        "\n",
        "**문장 벡터 활용: 문서 분류 등**\n",
        "\n",
        "**단어 벡터 활용: 개체명 인식 등**"
      ],
      "metadata": {
        "id": "Ygo8lcqMTT9J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 코드"
      ],
      "metadata": {
        "id": "sWs6A4BJVUeK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1단계"
      ],
      "metadata": {
        "id": "EUJRDfDeYKHq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L00cg1Zm0vN5",
        "outputId": "978b3bb6-ee5c-4117-a109-df618b6188e9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ratsnlp\n",
            "  Downloading ratsnlp-1.0.5-py3-none-any.whl (42 kB)\n",
            "\u001b[?25l\r\u001b[K     |███████▊                        | 10 kB 39.4 MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 20 kB 46.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 30 kB 42.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 40 kB 48.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 42 kB 1.1 MB/s \n",
            "\u001b[?25hCollecting Korpora>=0.2.0\n",
            "  Downloading Korpora-0.2.0-py3-none-any.whl (57 kB)\n",
            "\u001b[K     |████████████████████████████████| 57 kB 6.8 MB/s \n",
            "\u001b[?25hCollecting transformers==4.10.0\n",
            "  Downloading transformers-4.10.0-py3-none-any.whl (2.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.8 MB 52.7 MB/s \n",
            "\u001b[?25hCollecting flask-ngrok>=0.0.25\n",
            "  Downloading flask_ngrok-0.0.25-py3-none-any.whl (3.1 kB)\n",
            "Collecting flask-cors>=3.0.10\n",
            "  Downloading Flask_Cors-3.0.10-py2.py3-none-any.whl (14 kB)\n",
            "Collecting torchmetrics==0.7.3\n",
            "  Downloading torchmetrics-0.7.3-py3-none-any.whl (398 kB)\n",
            "\u001b[K     |████████████████████████████████| 398 kB 71.1 MB/s \n",
            "\u001b[?25hCollecting torchtext==0.11.0\n",
            "  Downloading torchtext-0.11.0-cp37-cp37m-manylinux1_x86_64.whl (8.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 8.0 MB 22.9 MB/s \n",
            "\u001b[?25hCollecting pytorch-lightning==1.3.4\n",
            "  Downloading pytorch_lightning-1.3.4-py3-none-any.whl (806 kB)\n",
            "\u001b[K     |████████████████████████████████| 806 kB 64.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: flask>=1.1.4 in /usr/local/lib/python3.7/dist-packages (from ratsnlp) (1.1.4)\n",
            "Requirement already satisfied: tensorboard!=2.5.0,>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.3.4->ratsnlp) (2.8.0)\n",
            "Collecting PyYAML<=5.4.1,>=5.1\n",
            "  Downloading PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636 kB)\n",
            "\u001b[K     |████████████████████████████████| 636 kB 61.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.3.4->ratsnlp) (21.3)\n",
            "Requirement already satisfied: torch>=1.4 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.3.4->ratsnlp) (1.11.0+cu113)\n",
            "Collecting pyDeprecate==0.3.0\n",
            "  Downloading pyDeprecate-0.3.0-py3-none-any.whl (10 kB)\n",
            "Collecting future>=0.17.1\n",
            "  Downloading future-0.18.2.tar.gz (829 kB)\n",
            "\u001b[K     |████████████████████████████████| 829 kB 39.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.3.4->ratsnlp) (4.64.0)\n",
            "Collecting fsspec[http]>=2021.4.0\n",
            "  Downloading fsspec-2022.3.0-py3-none-any.whl (136 kB)\n",
            "\u001b[K     |████████████████████████████████| 136 kB 68.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.3.4->ratsnlp) (1.21.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchtext==0.11.0->ratsnlp) (2.23.0)\n",
            "Collecting torch>=1.4\n",
            "  Downloading torch-1.10.0-cp37-cp37m-manylinux1_x86_64.whl (881.9 MB)\n",
            "\u001b[K     |██████████████████████████████▎ | 834.1 MB 1.1 MB/s eta 0:00:43tcmalloc: large alloc 1147494400 bytes == 0x3d5a000 @  0x7f60cc04c615 0x592b76 0x4df71e 0x59afff 0x515655 0x549576 0x593fce 0x548ae9 0x51566f 0x549576 0x593fce 0x548ae9 0x5127f1 0x598e3b 0x511f68 0x598e3b 0x511f68 0x598e3b 0x511f68 0x4bc98a 0x532e76 0x594b72 0x515600 0x549576 0x593fce 0x548ae9 0x5127f1 0x549576 0x593fce 0x5118f8 0x593dd7\n",
            "\u001b[K     |████████████████████████████████| 881.9 MB 17 kB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.4->pytorch-lightning==1.3.4->ratsnlp) (4.2.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.10.0->ratsnlp) (2019.12.20)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers==4.10.0->ratsnlp) (4.11.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==4.10.0->ratsnlp) (3.7.0)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n",
            "\u001b[K     |████████████████████████████████| 880 kB 61.4 MB/s \n",
            "\u001b[?25hCollecting huggingface-hub>=0.0.12\n",
            "  Downloading huggingface_hub-0.6.0-py3-none-any.whl (84 kB)\n",
            "\u001b[K     |████████████████████████████████| 84 kB 4.2 MB/s \n",
            "\u001b[?25hCollecting tokenizers<0.11,>=0.10.1\n",
            "  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 59.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: Werkzeug<2.0,>=0.15 in /usr/local/lib/python3.7/dist-packages (from flask>=1.1.4->ratsnlp) (1.0.1)\n",
            "Requirement already satisfied: Jinja2<3.0,>=2.10.1 in /usr/local/lib/python3.7/dist-packages (from flask>=1.1.4->ratsnlp) (2.11.3)\n",
            "Requirement already satisfied: itsdangerous<2.0,>=0.24 in /usr/local/lib/python3.7/dist-packages (from flask>=1.1.4->ratsnlp) (1.1.0)\n",
            "Requirement already satisfied: click<8.0,>=5.1 in /usr/local/lib/python3.7/dist-packages (from flask>=1.1.4->ratsnlp) (7.1.2)\n",
            "Requirement already satisfied: Six in /usr/local/lib/python3.7/dist-packages (from flask-cors>=3.0.10->ratsnlp) (1.15.0)\n",
            "Collecting aiohttp\n",
            "  Downloading aiohttp-3.8.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 63.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2<3.0,>=2.10.1->flask>=1.1.4->ratsnlp) (2.0.1)\n",
            "Collecting dataclasses>=0.6\n",
            "  Downloading dataclasses-0.6-py3-none-any.whl (14 kB)\n",
            "Collecting xlrd>=1.2.0\n",
            "  Downloading xlrd-2.0.1-py2.py3-none-any.whl (96 kB)\n",
            "\u001b[K     |████████████████████████████████| 96 kB 7.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->pytorch-lightning==1.3.4->ratsnlp) (3.0.9)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.11.0->ratsnlp) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.11.0->ratsnlp) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.11.0->ratsnlp) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.11.0->ratsnlp) (3.0.4)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.3.4->ratsnlp) (0.4.6)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.3.4->ratsnlp) (57.4.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.3.4->ratsnlp) (1.8.1)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.3.4->ratsnlp) (1.46.1)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.3.4->ratsnlp) (3.17.3)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.3.4->ratsnlp) (3.3.7)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.3.4->ratsnlp) (1.0.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.3.4->ratsnlp) (0.37.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.3.4->ratsnlp) (0.6.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.3.4->ratsnlp) (1.35.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.3.4->ratsnlp) (4.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.3.4->ratsnlp) (4.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.3.4->ratsnlp) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.3.4->ratsnlp) (1.3.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers==4.10.0->ratsnlp) (3.8.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.3.4->ratsnlp) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.3.4->ratsnlp) (3.2.0)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]>=2021.4.0->pytorch-lightning==1.3.4->ratsnlp) (2.0.12)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]>=2021.4.0->pytorch-lightning==1.3.4->ratsnlp) (21.4.0)\n",
            "Collecting multidict<7.0,>=4.5\n",
            "  Downloading multidict-6.0.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (94 kB)\n",
            "\u001b[K     |████████████████████████████████| 94 kB 4.4 MB/s \n",
            "\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Collecting yarl<2.0,>=1.0\n",
            "  Downloading yarl-1.7.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (271 kB)\n",
            "\u001b[K     |████████████████████████████████| 271 kB 82.2 MB/s \n",
            "\u001b[?25hCollecting asynctest==0.13.0\n",
            "  Downloading asynctest-0.13.0-py3-none-any.whl (26 kB)\n",
            "Collecting aiosignal>=1.1.2\n",
            "  Downloading aiosignal-1.2.0-py3-none-any.whl (8.2 kB)\n",
            "Collecting frozenlist>=1.1.1\n",
            "  Downloading frozenlist-1.3.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (144 kB)\n",
            "\u001b[K     |████████████████████████████████| 144 kB 88.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.10.0->ratsnlp) (1.1.0)\n",
            "Building wheels for collected packages: future, sacremoses\n",
            "  Building wheel for future (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for future: filename=future-0.18.2-py3-none-any.whl size=491070 sha256=76cb6491837ed7cc72180e02dffefcc3e587a285d3227956ac58fd7ecbb45bbe\n",
            "  Stored in directory: /root/.cache/pip/wheels/56/b0/fe/4410d17b32f1f0c3cf54cdfb2bc04d7b4b8f4ae377e2229ba0\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895260 sha256=0cbbd0b8a0faa07366f9b38f614f77bbb3943089bd1156b94dd26108373cb5a9\n",
            "  Stored in directory: /root/.cache/pip/wheels/87/39/dd/a83eeef36d0bf98e7a4d1933a4ad2d660295a40613079bafc9\n",
            "Successfully built future sacremoses\n",
            "Installing collected packages: multidict, frozenlist, yarl, asynctest, async-timeout, aiosignal, torch, PyYAML, pyDeprecate, fsspec, aiohttp, xlrd, torchmetrics, tokenizers, sacremoses, huggingface-hub, future, dataclasses, transformers, torchtext, pytorch-lightning, Korpora, flask-ngrok, flask-cors, ratsnlp\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.11.0+cu113\n",
            "    Uninstalling torch-1.11.0+cu113:\n",
            "      Successfully uninstalled torch-1.11.0+cu113\n",
            "  Attempting uninstall: PyYAML\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "  Attempting uninstall: xlrd\n",
            "    Found existing installation: xlrd 1.1.0\n",
            "    Uninstalling xlrd-1.1.0:\n",
            "      Successfully uninstalled xlrd-1.1.0\n",
            "  Attempting uninstall: future\n",
            "    Found existing installation: future 0.16.0\n",
            "    Uninstalling future-0.16.0:\n",
            "      Successfully uninstalled future-0.16.0\n",
            "  Attempting uninstall: torchtext\n",
            "    Found existing installation: torchtext 0.12.0\n",
            "    Uninstalling torchtext-0.12.0:\n",
            "      Successfully uninstalled torchtext-0.12.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchvision 0.12.0+cu113 requires torch==1.11.0, but you have torch 1.10.0 which is incompatible.\n",
            "torchaudio 0.11.0+cu113 requires torch==1.11.0, but you have torch 1.10.0 which is incompatible.\u001b[0m\n",
            "Successfully installed Korpora-0.2.0 PyYAML-5.4.1 aiohttp-3.8.1 aiosignal-1.2.0 async-timeout-4.0.2 asynctest-0.13.0 dataclasses-0.6 flask-cors-3.0.10 flask-ngrok-0.0.25 frozenlist-1.3.0 fsspec-2022.3.0 future-0.18.2 huggingface-hub-0.6.0 multidict-6.0.2 pyDeprecate-0.3.0 pytorch-lightning-1.3.4 ratsnlp-1.0.5 sacremoses-0.0.53 tokenizers-0.10.3 torch-1.10.0 torchmetrics-0.7.3 torchtext-0.11.0 transformers-4.10.0 xlrd-2.0.1 yarl-1.7.2\n"
          ]
        }
      ],
      "source": [
        "!pip install ratsnlp"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2단계 토크나이저 초기화"
      ],
      "metadata": {
        "id": "wqvbCf7uYSid"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#토크나이저 선언\n",
        "## BERT(kcbert-base) 모델이 쓰는 토크나이저를 선언\n",
        "from transformers import BertTokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained(\n",
        "    \"beomi/kcbert-base\",\n",
        "    do_lower_case=False,\n",
        ")"
      ],
      "metadata": {
        "id": "fAQhUX4dWOv-"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# BERT(kcbert-base) 모델을 읽기\n",
        "from transformers import BertConfig, BertModel\n",
        "pretrained_model_config = BertConfig.from_pretrained(\n",
        "    \"beomi/kcbert-base\"\n",
        ")\n",
        "model = BertModel.from_pretrained(\n",
        "    \"beomi/kcbert-base\",\n",
        "    config=pretrained_model_config,\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151,
          "referenced_widgets": [
            "aa178a5b9c154d4baac3686d740e83ad",
            "769b5d2442ec4d44b5294b9c6101893d",
            "e7dc6c48fed84690a806291e29a74704",
            "1235482fd89e481cbbe59cf1f0ddd667",
            "742e06c227ec49c48ee90d2ea4887ff2",
            "0e2b39ea07184c50b41f486a36d14422",
            "43cc958b8b87442d84183bd8a5abc666",
            "5ff0ee291c8a4b9c9df24b8b5b863f42",
            "04af07c986204789bd33c6437b4884b6",
            "206bf0bf0bdb4668a7b30d76207b36cc",
            "f54057ce3c3546e199a2e834eb914b01"
          ]
        },
        "id": "W9YOgrbmWgtY",
        "outputId": "36824300-5fa2-4c1f-f633-31b0c44365d1"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/438M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "aa178a5b9c154d4baac3686d740e83ad"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at beomi/kcbert-base were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#pretrained_model_config의 내용을 확인\n",
        "pretrained_model_config"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XBW7HFdqXD7_",
        "outputId": "63bd5db8-3ba1-4bf2-d1de-4ab361abd177"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertConfig {\n",
              "  \"_name_or_path\": \"beomi/kcbert-base\",\n",
              "  \"architectures\": [\n",
              "    \"BertForMaskedLM\"\n",
              "  ],\n",
              "  \"attention_probs_dropout_prob\": 0.1,\n",
              "  \"classifier_dropout\": null,\n",
              "  \"directionality\": \"bidi\",\n",
              "  \"gradient_checkpointing\": false,\n",
              "  \"hidden_act\": \"gelu\",\n",
              "  \"hidden_dropout_prob\": 0.1,\n",
              "  \"hidden_size\": 768,\n",
              "  \"initializer_range\": 0.02,\n",
              "  \"intermediate_size\": 3072,\n",
              "  \"layer_norm_eps\": 1e-12,\n",
              "  \"max_position_embeddings\": 300,\n",
              "  \"model_type\": \"bert\",\n",
              "  \"num_attention_heads\": 12,\n",
              "  \"num_hidden_layers\": 12,\n",
              "  \"pad_token_id\": 0,\n",
              "  \"pooler_fc_size\": 768,\n",
              "  \"pooler_num_attention_heads\": 12,\n",
              "  \"pooler_num_fc_layers\": 3,\n",
              "  \"pooler_size_per_head\": 128,\n",
              "  \"pooler_type\": \"first_token_transform\",\n",
              "  \"position_embedding_type\": \"absolute\",\n",
              "  \"transformers_version\": \"4.10.0\",\n",
              "  \"type_vocab_size\": 2,\n",
              "  \"use_cache\": true,\n",
              "  \"vocab_size\": 30000\n",
              "}"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3단계 입력값 만들기"
      ],
      "metadata": {
        "id": "SdgRDbA0XNe-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = [\"안녕하세요\", \"하이!\"]\n",
        "features = tokenizer(\n",
        "    sentences,\n",
        "    max_length=10,\n",
        "    padding=\"max_length\",\n",
        "    truncation=True,\n",
        ")"
      ],
      "metadata": {
        "id": "1jtaCCNAXJ-c"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features.keys()\n",
        "#features['input_ids']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OrGeeZbwXTW4",
        "outputId": "6de68c2d-9a04-4e88-8249-863de192d48e"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['input_ids', 'token_type_ids', 'attention_mask'])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "BERT 임베딩 추출"
      ],
      "metadata": {
        "id": "60t1gL-vXdTZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#피처를 토치 텐서로 변환\n",
        "import torch\n",
        "features = {k: torch.tensor(v) for k, v in features.items()}\n",
        "#BERT 모델에 features를 입력해 계산\n",
        "outputs = model(**features)\n",
        "\n",
        "#BERT 마지막 레이어의 단어 수준 벡터들을 확인\n",
        "outputs.last_hidden_state\n",
        "# #BERT 마지막 레이어의 문서 수준 벡터를 확인\n",
        "# outputs.pooler_output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ECZ9KaFAXWfB",
        "outputId": "abc5c1f3-ac61-4683-aa79-dc104022546e"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[-0.6969, -0.8248,  1.7512,  ..., -0.3732,  0.7399,  1.1907],\n",
              "         [-1.4803, -0.4398,  0.9444,  ..., -0.7405, -0.0211,  1.3064],\n",
              "         [-1.4300, -0.5033, -0.2069,  ...,  0.1285, -0.2611,  1.6057],\n",
              "         ...,\n",
              "         [-1.4406,  0.3431,  1.4043,  ..., -0.0565,  0.8450, -0.2170],\n",
              "         [-1.3625, -0.2404,  1.1757,  ...,  0.8876, -0.1054,  0.0734],\n",
              "         [-1.4244,  0.1518,  1.2920,  ...,  0.0245,  0.7572,  0.0080]],\n",
              "\n",
              "        [[ 0.9371, -1.4749,  1.7351,  ..., -0.3426,  0.8050,  0.4031],\n",
              "         [ 1.6095, -1.7269,  2.7936,  ...,  0.3100, -0.4787, -1.2491],\n",
              "         [ 0.4861, -0.4569,  0.5712,  ..., -0.1769,  1.1253, -0.2756],\n",
              "         ...,\n",
              "         [ 1.2362, -0.6181,  2.0906,  ...,  1.3677,  0.8132, -0.2742],\n",
              "         [ 0.5409, -0.9652,  1.6237,  ...,  1.2395,  0.9185,  0.1782],\n",
              "         [ 1.9001, -0.5859,  3.0156,  ...,  1.4967,  0.1924, -0.4448]]],\n",
              "       grad_fn=<NativeLayerNormBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    }
  ]
}