{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2장 문장을 작은 단위로 쪼개기.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 문장을 작은 단위로 쪼개기"
      ],
      "metadata": {
        "id": "Ev4Q2_6DMExD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2-1 토큰화란?"
      ],
      "metadata": {
        "id": "OqB6avpCMJlS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**토큰화**란 문장을 **토큰 시퀀스**로 나누는 과정\n",
        " 문자 단어 서브워드 등의 방법이 있다.\n",
        " ### 단어 단위 토큰화\n",
        "- 단어(어절)단위\n",
        "- 공백으로 분리하여 토크나이저 안써도됨\n",
        "- 어휘 집합의 크기가 커짐 \n",
        "### 문자 단위 토큰화\n",
        "- 해당 언어의 모든 문자를 어휘집화\n",
        "  - 미등록 토큰 문제가 없음(신조어에 유리)\n",
        "- 각 문자 토큰은 의미있는 단위가 되기 어려움\n",
        "- 토큰의 시퀀스 길이가 길어짐\n",
        "### 서브워드 단위 토큰화\n",
        "- 단어와 문자 돤위의 중간\n",
        "- 예: 바이트 페어 인코딩"
      ],
      "metadata": {
        "id": "CRngaE8O4kQV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## 2-2 바이트 페어 인코딩이란?\n"
      ],
      "metadata": {
        "id": "X8_igZJnMIhz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**바이트 페어 인코딩** 정보를 압축하는 알고리즘에서 최초 사용\n",
        "GPT=BPE사용\n",
        "Bert=워드피스 사용\n",
        "### BPE란\n",
        "데이터에서 가장 많이 사용한 **문자열을 병합**해서 데이터를 압축하는 기법\n",
        "- aaabdaaabac\n",
        "- ZabdZabac\n",
        "- ZYdZTac\n",
        "- XdXac\n",
        "\n",
        "사전 크기 증가를 억제하면서도 정보를 효율적으로 압축할 수 있는 알고리즘\n",
        "### BPE 어휘집 구축하기\n",
        "**고빈도 바이그램 쌍을 병합하는 방식으로 구축함**\n",
        "1. 프리토크나이즈(말뭉치의 모든 문장을 공백으로 나누기/다른 기준도 OK)\n",
        "  - h,u,g: 10\n",
        "2.토큰을 2개씩 묶어서 나열( 쌍이 같은 것 끼리 합치기 포함)\n",
        "3. 가장 많이 등장한 바이그램 쌍을 어휘 집합에 추가\n",
        "4. 1부터 다시 반복(어취집합의 크기가 사용자 지정에 도달할 때 까지)\n",
        "  - 어휘 집합(voca.json) 구축 결과\n",
        "    - b,g,h,n,p,s,u,ug,un,hug\n",
        "  -병합 우선순위(merge.text)병합 결과 기록 저장한것\n",
        "    - u g\n",
        "    - u n\n",
        "    - h ug\n",
        "\n",
        "### BPE 토큰화\n",
        "어휘 집합(voca.json)과 병합 우선순위(merge.text)를 가지고 함\n",
        "예\n",
        "  pug, bug, mug\n",
        "  p, ug, b, ug, \\<unk\\>, ug\n",
        "일반적으로 개별문자(알파벳)등은 처음 어휘 집합에 들어가므로 **미등록 토큰이 거의 없다**.=> 신조어에 유의미한 분절 수행가능\n",
        "### 워드피스\n",
        "말뭉치에서 자주 등장한 문자열 토큰화(BPE와 유사)\n",
        "But**말뭉치의 우도를 가장 높이는 쌍을 병합**\n",
        "a,b,ab라는 문자열이 n의 글자수에서 나오는 것 가정\n",
        "(#ab/n)/(#a/n)*((#b/n)\n",
        "- a,b가 독립일때, 위식에 값이 커야 동시에 등장 함\n"
      ],
      "metadata": {
        "id": "KO0Af_uQOadU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2-3 어휘 집합 구축하기\n"
      ],
      "metadata": {
        "id": "DOFSn1hWMIXk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1,2단계"
      ],
      "metadata": {
        "id": "o9cCiOAR6eg6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ratsnlp"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jBZynKM-PvX7",
        "outputId": "b4af90da-ee3a-4045-c506-37ba35377b3d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ratsnlp in /usr/local/lib/python3.7/dist-packages (1.0.5)\n",
            "Requirement already satisfied: Korpora>=0.2.0 in /usr/local/lib/python3.7/dist-packages (from ratsnlp) (0.2.0)\n",
            "Requirement already satisfied: flask-cors>=3.0.10 in /usr/local/lib/python3.7/dist-packages (from ratsnlp) (3.0.10)\n",
            "Requirement already satisfied: flask-ngrok>=0.0.25 in /usr/local/lib/python3.7/dist-packages (from ratsnlp) (0.0.25)\n",
            "Requirement already satisfied: torchtext==0.11.0 in /usr/local/lib/python3.7/dist-packages (from ratsnlp) (0.11.0)\n",
            "Requirement already satisfied: flask>=1.1.4 in /usr/local/lib/python3.7/dist-packages (from ratsnlp) (1.1.4)\n",
            "Requirement already satisfied: transformers==4.10.0 in /usr/local/lib/python3.7/dist-packages (from ratsnlp) (4.10.0)\n",
            "Requirement already satisfied: torchmetrics==0.7.3 in /usr/local/lib/python3.7/dist-packages (from ratsnlp) (0.7.3)\n",
            "Requirement already satisfied: pytorch-lightning==1.3.4 in /usr/local/lib/python3.7/dist-packages (from ratsnlp) (1.3.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.3.4->ratsnlp) (21.3)\n",
            "Requirement already satisfied: torch>=1.4 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.3.4->ratsnlp) (1.10.0)\n",
            "Requirement already satisfied: tensorboard!=2.5.0,>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.3.4->ratsnlp) (2.8.0)\n",
            "Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.3.4->ratsnlp) (1.21.6)\n",
            "Requirement already satisfied: fsspec[http]>=2021.4.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.3.4->ratsnlp) (2022.3.0)\n",
            "Requirement already satisfied: future>=0.17.1 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.3.4->ratsnlp) (0.18.2)\n",
            "Requirement already satisfied: PyYAML<=5.4.1,>=5.1 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.3.4->ratsnlp) (5.4.1)\n",
            "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.3.4->ratsnlp) (4.64.0)\n",
            "Requirement already satisfied: pyDeprecate==0.3.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.3.4->ratsnlp) (0.3.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchtext==0.11.0->ratsnlp) (2.23.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.4->pytorch-lightning==1.3.4->ratsnlp) (4.2.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.10.0->ratsnlp) (2019.12.20)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers==4.10.0->ratsnlp) (4.11.3)\n",
            "Requirement already satisfied: huggingface-hub>=0.0.12 in /usr/local/lib/python3.7/dist-packages (from transformers==4.10.0->ratsnlp) (0.6.0)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers==4.10.0->ratsnlp) (0.0.53)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers==4.10.0->ratsnlp) (0.10.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==4.10.0->ratsnlp) (3.7.0)\n",
            "Requirement already satisfied: itsdangerous<2.0,>=0.24 in /usr/local/lib/python3.7/dist-packages (from flask>=1.1.4->ratsnlp) (1.1.0)\n",
            "Requirement already satisfied: Jinja2<3.0,>=2.10.1 in /usr/local/lib/python3.7/dist-packages (from flask>=1.1.4->ratsnlp) (2.11.3)\n",
            "Requirement already satisfied: Werkzeug<2.0,>=0.15 in /usr/local/lib/python3.7/dist-packages (from flask>=1.1.4->ratsnlp) (1.0.1)\n",
            "Requirement already satisfied: click<8.0,>=5.1 in /usr/local/lib/python3.7/dist-packages (from flask>=1.1.4->ratsnlp) (7.1.2)\n",
            "Requirement already satisfied: Six in /usr/local/lib/python3.7/dist-packages (from flask-cors>=3.0.10->ratsnlp) (1.15.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.7/dist-packages (from fsspec[http]>=2021.4.0->pytorch-lightning==1.3.4->ratsnlp) (3.8.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2<3.0,>=2.10.1->flask>=1.1.4->ratsnlp) (2.0.1)\n",
            "Requirement already satisfied: xlrd>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from Korpora>=0.2.0->ratsnlp) (2.0.1)\n",
            "Requirement already satisfied: dataclasses>=0.6 in /usr/local/lib/python3.7/dist-packages (from Korpora>=0.2.0->ratsnlp) (0.6)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->pytorch-lightning==1.3.4->ratsnlp) (3.0.9)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.11.0->ratsnlp) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.11.0->ratsnlp) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.11.0->ratsnlp) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.11.0->ratsnlp) (1.24.3)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.3.4->ratsnlp) (0.37.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.3.4->ratsnlp) (3.3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.3.4->ratsnlp) (0.6.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.3.4->ratsnlp) (0.4.6)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.3.4->ratsnlp) (1.35.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.3.4->ratsnlp) (1.0.0)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.3.4->ratsnlp) (1.46.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.3.4->ratsnlp) (57.4.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.3.4->ratsnlp) (1.8.1)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.3.4->ratsnlp) (3.17.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.3.4->ratsnlp) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.3.4->ratsnlp) (4.2.4)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.3.4->ratsnlp) (4.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.3.4->ratsnlp) (1.3.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers==4.10.0->ratsnlp) (3.8.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.3.4->ratsnlp) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.3.4->ratsnlp) (3.2.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]>=2021.4.0->pytorch-lightning==1.3.4->ratsnlp) (21.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]>=2021.4.0->pytorch-lightning==1.3.4->ratsnlp) (1.3.0)\n",
            "Requirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]>=2021.4.0->pytorch-lightning==1.3.4->ratsnlp) (0.13.0)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]>=2021.4.0->pytorch-lightning==1.3.4->ratsnlp) (2.0.12)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]>=2021.4.0->pytorch-lightning==1.3.4->ratsnlp) (6.0.2)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]>=2021.4.0->pytorch-lightning==1.3.4->ratsnlp) (1.2.0)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]>=2021.4.0->pytorch-lightning==1.3.4->ratsnlp) (4.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]>=2021.4.0->pytorch-lightning==1.3.4->ratsnlp) (1.7.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.10.0->ratsnlp) (1.1.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#드라이브 연결\n",
        "from google.colab import drive\n",
        "drive.mount('/gdrive', force_remount=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qeo7ERtyVLjy",
        "outputId": "f1c3218f-e481-4025-a203-f8144bb63964"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3단계 말뭉치 내려받기 및 전처리"
      ],
      "metadata": {
        "id": "Nrglhd3kW_bm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#말뭉치 내려받기 및 전처리\n",
        "from Korpora import Korpora\n",
        "nsmc = Korpora.load(\"nsmc\", force_download=True)\n",
        "##말뭉치는 박은정 님이 공개하신 Naver Sentiment Movie Corpus(NSMC)"
      ],
      "metadata": {
        "id": "30aOUPL_VS7s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "03efc321-8629-462e-8612-aa4a66d25a22"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "    Korpora 는 다른 분들이 연구 목적으로 공유해주신 말뭉치들을\n",
            "    손쉽게 다운로드, 사용할 수 있는 기능만을 제공합니다.\n",
            "\n",
            "    말뭉치들을 공유해 주신 분들에게 감사드리며, 각 말뭉치 별 설명과 라이센스를 공유 드립니다.\n",
            "    해당 말뭉치에 대해 자세히 알고 싶으신 분은 아래의 description 을 참고,\n",
            "    해당 말뭉치를 연구/상용의 목적으로 이용하실 때에는 아래의 라이센스를 참고해 주시기 바랍니다.\n",
            "\n",
            "    # Description\n",
            "    Author : e9t@github\n",
            "    Repository : https://github.com/e9t/nsmc\n",
            "    References : www.lucypark.kr/docs/2015-pyconkr/#39\n",
            "\n",
            "    Naver sentiment movie corpus v1.0\n",
            "    This is a movie review dataset in the Korean language.\n",
            "    Reviews were scraped from Naver Movies.\n",
            "\n",
            "    The dataset construction is based on the method noted in\n",
            "    [Large movie review dataset][^1] from Maas et al., 2011.\n",
            "\n",
            "    [^1]: http://ai.stanford.edu/~amaas/data/sentiment/\n",
            "\n",
            "    # License\n",
            "    CC0 1.0 Universal (CC0 1.0) Public Domain Dedication\n",
            "    Details in https://creativecommons.org/publicdomain/zero/1.0/\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nsmc] download ratings_train.txt: 14.6MB [00:00, 134MB/s]                            \n",
            "[nsmc] download ratings_test.txt: 4.90MB [00:00, 71.4MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#NSMC 전처리\n",
        "import os\n",
        "def write_lines(path, lines):\n",
        "    with open(path, 'w', encoding='utf-8') as f:\n",
        "        for line in lines:\n",
        "            f.write(f'{line}\\n')\n",
        "\n",
        "write_lines(\"/content/train.txt\", nsmc.train.get_all_texts())\n",
        "write_lines(\"/content/test.txt\", nsmc.test.get_all_texts())\n",
        "\n",
        "#NSMC에 포함된 영화 리뷰(순수 텍스트)들을 지정된 경로에 저장"
      ],
      "metadata": {
        "id": "Wlu9tI6iWLKF"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!head train.txt\n",
        "#!head test.txt"
      ],
      "metadata": {
        "id": "5iAoF5IeXrMv"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4단계 GPT토크나이저 구축\n",
        "GPT 계열 모델이 사용하는 토크나이저는 Byte-level Byte Pair Encoding(BBPE)\n",
        "**유니바코드 수준으로 어휘 집합을 구축하고 토큰화를 수행**\n",
        "한글의 경우 3개의 유니코드바이트로 한 글자가 표현됨"
      ],
      "metadata": {
        "id": "KcRvHmJPW5aq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#디렉토리 만들기\n",
        "import os\n",
        "os.makedirs(\"/gdrive/My Drive/nlpbook/bbpe\", exist_ok=True)"
      ],
      "metadata": {
        "id": "gqOBPvizXmSb"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# nsmc 데이터를 가지고 BBPE 어휘집합을 구축\n",
        "from tokenizers import ByteLevelBPETokenizer\n",
        "bytebpe_tokenizer = ByteLevelBPETokenizer()\n",
        "bytebpe_tokenizer.train(\n",
        "    files=[\"/content/train.txt\", \"/content/test.txt\"],#학습 말뭉치를 리스트 형태로 넣기\n",
        "    vocab_size=10000,#어휘 집합의 크기\n",
        "    special_tokens=[\"[PAD]\"] #특수 토큰 추가\n",
        ")\n",
        "bytebpe_tokenizer.save_model(\"/gdrive/My Drive/nlpbook/bbpe\")\n",
        "\n",
        "## vocab.json은 바이트 레벨 BPE의 어휘 집합\n",
        "## merges.txt는 바이그램 쌍의 병합 우선순위\n"
      ],
      "metadata": {
        "id": "7uKeu69FYHgJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e0826d95-d970-48f9-fef7-dc4b96e096dc"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/gdrive/My Drive/nlpbook/bbpe/vocab.json',\n",
              " '/gdrive/My Drive/nlpbook/bbpe/merges.txt']"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# vocab.json\n",
        "# !cat /gdrive/My\\ Drive/nlpbook/bbpe/vocab.json\n",
        "# merges.txt\n",
        "# !head /gdrive/My\\ Drive/nlpbook/bbpe/merges.txt"
      ],
      "metadata": {
        "id": "SUDsJYFFZMWM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "5 단계 BERT토크나이저 구축"
      ],
      "metadata": {
        "id": "-V5xFEj3Zdvw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "BERT는 워드피스(wordpiece) 토크나이저를 사용"
      ],
      "metadata": {
        "id": "U_WT4sAwZ2Z-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 디렉터리 만들기\n",
        "import os\n",
        "os.makedirs(\"/gdrive/My Drive/nlpbook/wordpiece\", exist_ok=True)"
      ],
      "metadata": {
        "id": "KByBIkvfZoql"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#워드피스 어휘 집합 구축\n",
        "from tokenizers import BertWordPieceTokenizer\n",
        "wordpiece_tokenizer = BertWordPieceTokenizer(lowercase=False)\n",
        "wordpiece_tokenizer.train(\n",
        "    files=[\"/content/train.txt\", \"/content/test.txt\"],\n",
        "    vocab_size=10000,\n",
        ")\n",
        "wordpiece_tokenizer.save_model(\"/gdrive/My Drive/nlpbook/wordpiece\")"
      ],
      "metadata": {
        "id": "7p2M4GGEZrcF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4df5ebb6-e682-4d70-a44d-3a39816715b0"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/gdrive/My Drive/nlpbook/wordpiece/vocab.txt']"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#구축 결과\n",
        "#!head /gdrive/My\\ Drive/nlpbook/wordpiece/vocab.txt"
      ],
      "metadata": {
        "id": "BO8i18tMZuCS"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2-4 토큰화하기\n"
      ],
      "metadata": {
        "id": "UPQrIsczMH83"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "문장을 토큰화 + 토큰을 모델에 입력"
      ],
      "metadata": {
        "id": "0Fvooyiaadpm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ratsnlp\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/gdrive', force_remount=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XtWNFHuhZTz2",
        "outputId": "e9f89053-4c95-4b25-d84e-83d811a1a6aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ratsnlp in /usr/local/lib/python3.7/dist-packages (1.0.5)\n",
            "Requirement already satisfied: torchmetrics==0.7.3 in /usr/local/lib/python3.7/dist-packages (from ratsnlp) (0.7.3)\n",
            "Requirement already satisfied: flask>=1.1.4 in /usr/local/lib/python3.7/dist-packages (from ratsnlp) (1.1.4)\n",
            "Requirement already satisfied: pytorch-lightning==1.3.4 in /usr/local/lib/python3.7/dist-packages (from ratsnlp) (1.3.4)\n",
            "Requirement already satisfied: torchtext==0.11.0 in /usr/local/lib/python3.7/dist-packages (from ratsnlp) (0.11.0)\n",
            "Requirement already satisfied: Korpora>=0.2.0 in /usr/local/lib/python3.7/dist-packages (from ratsnlp) (0.2.0)\n",
            "Requirement already satisfied: transformers==4.10.0 in /usr/local/lib/python3.7/dist-packages (from ratsnlp) (4.10.0)\n",
            "Requirement already satisfied: flask-ngrok>=0.0.25 in /usr/local/lib/python3.7/dist-packages (from ratsnlp) (0.0.25)\n",
            "Requirement already satisfied: flask-cors>=3.0.10 in /usr/local/lib/python3.7/dist-packages (from ratsnlp) (3.0.10)\n",
            "Requirement already satisfied: torch>=1.4 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.3.4->ratsnlp) (1.10.0)\n",
            "Requirement already satisfied: tensorboard!=2.5.0,>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.3.4->ratsnlp) (2.8.0)\n",
            "Requirement already satisfied: pyDeprecate==0.3.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.3.4->ratsnlp) (0.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.3.4->ratsnlp) (21.3)\n",
            "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.3.4->ratsnlp) (4.64.0)\n",
            "Requirement already satisfied: fsspec[http]>=2021.4.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.3.4->ratsnlp) (2022.3.0)\n",
            "Requirement already satisfied: future>=0.17.1 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.3.4->ratsnlp) (0.18.2)\n",
            "Requirement already satisfied: PyYAML<=5.4.1,>=5.1 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.3.4->ratsnlp) (5.4.1)\n",
            "Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.3.4->ratsnlp) (1.21.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchtext==0.11.0->ratsnlp) (2.23.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.4->pytorch-lightning==1.3.4->ratsnlp) (4.2.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==4.10.0->ratsnlp) (3.7.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers==4.10.0->ratsnlp) (4.11.3)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers==4.10.0->ratsnlp) (0.0.53)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.10.0->ratsnlp) (2019.12.20)\n",
            "Requirement already satisfied: huggingface-hub>=0.0.12 in /usr/local/lib/python3.7/dist-packages (from transformers==4.10.0->ratsnlp) (0.6.0)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers==4.10.0->ratsnlp) (0.10.3)\n",
            "Requirement already satisfied: Jinja2<3.0,>=2.10.1 in /usr/local/lib/python3.7/dist-packages (from flask>=1.1.4->ratsnlp) (2.11.3)\n",
            "Requirement already satisfied: itsdangerous<2.0,>=0.24 in /usr/local/lib/python3.7/dist-packages (from flask>=1.1.4->ratsnlp) (1.1.0)\n",
            "Requirement already satisfied: Werkzeug<2.0,>=0.15 in /usr/local/lib/python3.7/dist-packages (from flask>=1.1.4->ratsnlp) (1.0.1)\n",
            "Requirement already satisfied: click<8.0,>=5.1 in /usr/local/lib/python3.7/dist-packages (from flask>=1.1.4->ratsnlp) (7.1.2)\n",
            "Requirement already satisfied: Six in /usr/local/lib/python3.7/dist-packages (from flask-cors>=3.0.10->ratsnlp) (1.15.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.7/dist-packages (from fsspec[http]>=2021.4.0->pytorch-lightning==1.3.4->ratsnlp) (3.8.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2<3.0,>=2.10.1->flask>=1.1.4->ratsnlp) (2.0.1)\n",
            "Requirement already satisfied: xlrd>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from Korpora>=0.2.0->ratsnlp) (2.0.1)\n",
            "Requirement already satisfied: dataclasses>=0.6 in /usr/local/lib/python3.7/dist-packages (from Korpora>=0.2.0->ratsnlp) (0.6)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->pytorch-lightning==1.3.4->ratsnlp) (3.0.9)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.11.0->ratsnlp) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.11.0->ratsnlp) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.11.0->ratsnlp) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.11.0->ratsnlp) (2021.10.8)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.3.4->ratsnlp) (0.37.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.3.4->ratsnlp) (0.6.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.3.4->ratsnlp) (3.3.7)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.3.4->ratsnlp) (1.8.1)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.3.4->ratsnlp) (1.0.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.3.4->ratsnlp) (57.4.0)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.3.4->ratsnlp) (1.46.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.3.4->ratsnlp) (1.35.0)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.3.4->ratsnlp) (3.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.3.4->ratsnlp) (0.4.6)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.3.4->ratsnlp) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.3.4->ratsnlp) (4.2.4)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.3.4->ratsnlp) (4.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.3.4->ratsnlp) (1.3.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers==4.10.0->ratsnlp) (3.8.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.3.4->ratsnlp) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.3.4->ratsnlp) (3.2.0)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]>=2021.4.0->pytorch-lightning==1.3.4->ratsnlp) (4.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]>=2021.4.0->pytorch-lightning==1.3.4->ratsnlp) (1.7.2)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]>=2021.4.0->pytorch-lightning==1.3.4->ratsnlp) (6.0.2)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]>=2021.4.0->pytorch-lightning==1.3.4->ratsnlp) (1.2.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]>=2021.4.0->pytorch-lightning==1.3.4->ratsnlp) (21.4.0)\n",
            "Requirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]>=2021.4.0->pytorch-lightning==1.3.4->ratsnlp) (0.13.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]>=2021.4.0->pytorch-lightning==1.3.4->ratsnlp) (1.3.0)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]>=2021.4.0->pytorch-lightning==1.3.4->ratsnlp) (2.0.12)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.10.0->ratsnlp) (1.1.0)\n",
            "Mounted at /gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2단계 GPT 입력값 만들기"
      ],
      "metadata": {
        "id": "q8G-7byYbGLp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#GPT 모델 입력값을 만들려면 Byte-level Byte Pair Encoding \n",
        "#어휘집합 구축 결과(vocab.json, merges.txt)가 \n",
        "#자신의 구글 드라이브 경로(/gdrive/My Drive/nlpbook/wordpiece)에 있어야 함\n",
        "\n",
        "#토크나이저 선언\n",
        "from transformers import GPT2Tokenizer\n",
        "tokenizer_gpt = GPT2Tokenizer.from_pretrained(\"/gdrive/My Drive/nlpbook/bbpe\")\n",
        "tokenizer_gpt.pad_token = \"[PAD]\""
      ],
      "metadata": {
        "id": "EkIGQDgpbQBX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f3afa559-5e90-4367-89bc-39a4fe4b128e"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "file /gdrive/My Drive/nlpbook/bbpe/config.json not found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#토크나이저로 토큰화 하기\n",
        "sentences = [\n",
        "    \"아 더빙.. 진짜 짜증나네요 목소리\",\n",
        "    \"흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나\",\n",
        "    \"별루 였다..\",\n",
        "]\n",
        "tokenized_sentences = [tokenizer_gpt.tokenize(sentence) for sentence in sentences]\n",
        "##토큰화결과\n",
        "# tokenized_sentences"
      ],
      "metadata": {
        "id": "HbzBkfuhbxYd"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 입력 만들기\n",
        "sentences = [\n",
        "    \"아 더빙.. 진짜 짜증나네요 목소리\",\n",
        "    \"흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나\",\n",
        "    \"별루 였다..\",\n",
        "]\n",
        "batch_inputs = tokenizer_gpt(\n",
        "    sentences,\n",
        "    padding=\"max_length\",#문장의 최대 길이에 맞춰 패딩\n",
        "    max_length=12,#문장의 토큰 기준 최대 길이\n",
        "                  #문장1,3에는 뒤에 [PAD]토큰에 해당하는 인덱스0이 붙는다.\n",
        "                  #[PAD]는 일종의 더미 변수임\n",
        "    truncation=True,#문장 잘림 허용 옵션\n",
        "                    #문장 2의 경우 15 토큰이여야 하지만 12로 잘렸고 이를 허용하는 것임\n",
        ")\n",
        "## 배치의 크기가 3이라 가정"
      ],
      "metadata": {
        "id": "wx9auUceyopb"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**input_ids**와 **attention_mask**가 만들어짐\n",
        "전자는 토큰화 결과를 가지고 각 토큰을 인텍스로 바꾼것(인덱싱 한것)\n",
        "어휘집(vocab.jason)을 확인해보면 어휘 순서대로 나열 확인 이 순서가 인덱스임\n",
        "\n",
        "후자는 일반토큰이 자리한곳(1)과 패딩 토큰이 자리한 곳을 구분해주는 장치\n"
      ],
      "metadata": {
        "id": "Ptiwa0Ym1tSJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(batch_inputs.keys())\n",
        "batch_inputs['input_ids']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bKhnsfTt0FHd",
        "outputId": "e8718950-0a17-4641-c077-c5720fd3e038"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['input_ids', 'attention_mask'])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[334, 2338, 263, 581, 4055, 464, 3808, 0, 0, 0, 0, 0],\n",
              " [3693, 336, 2876, 758, 2883, 356, 806, 422, 9875, 875, 2960, 7292],\n",
              " [4957, 451, 3653, 263, 0, 0, 0, 0, 0, 0, 0, 0]]"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_inputs['attention_mask']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lIGyLVnI8CXM",
        "outputId": "6dc42f75-0c8d-4076-cb6b-efb81ec789ae"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0],\n",
              " [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
              " [1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]]"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3단계 BERT 입력값 만들기"
      ],
      "metadata": {
        "id": "ecs5XQt333LB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "BERT 모델 입력값을 만들려면 자신의 구글 드라이브 경로(/gdrive/My Drive/nlpbook/wordpiece)에 워드피스 어휘집합 구축 결과(vocab.txt)가 있어야"
      ],
      "metadata": {
        "id": "5RAJaTZ84PEb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#BERT 토크나이저 선언\n",
        "from transformers import BertTokenizer\n",
        "tokenizer_bert = BertTokenizer.from_pretrained(\n",
        "    \"/gdrive/My Drive/nlpbook/wordpiece\", \n",
        "    do_lower_case=False,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "btSE6QYq32ZW",
        "outputId": "e96d76d1-0294-4d4e-f93b-ee058c476feb"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "file /gdrive/My Drive/nlpbook/wordpiece/config.json not found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#BERT 토크나이저로 토큰화 하기\n",
        "sentences = [\n",
        "    \"아 더빙.. 진짜 짜증나네요 목소리\",\n",
        "    \"흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나\",\n",
        "    \"별루 였다..\",\n",
        "]\n",
        "tokenized_sentences = [tokenizer_bert.tokenize(sentence) for sentence in sentences]\n",
        "#tokenized_sentences"
      ],
      "metadata": {
        "id": "RJobFzw24P88"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#모델 입력 만들기\n",
        "sentences = [\n",
        "    \"아 더빙.. 진짜 짜증나네요 목소리\",\n",
        "    \"흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나\",\n",
        "    \"별루 였다..\",\n",
        "]\n",
        "batch_inputs = tokenizer_bert(\n",
        "    sentences,\n",
        "    padding=\"max_length\",\n",
        "    max_length=12,\n",
        "    truncation=True,\n",
        ")"
      ],
      "metadata": {
        "id": "zsWRPpew4TXC"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_inputs.keys()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6pDrpphR5Br-",
        "outputId": "200c7817-b0ac-498b-e05d-b9cbe85f9309"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['input_ids', 'token_type_ids', 'attention_mask'])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_inputs['input_ids']\n",
        "#문장 처음에 2([CLS]) 끝에는 3([SEP])이 붙음\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KleiPv4s5Dt2",
        "outputId": "69645218-f66e-46be-ac6a-4571e4bb4606"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[2, 620, 2631, 16, 16, 1993, 3678, 1990, 3323, 3, 0, 0],\n",
              " [2, 997, 16, 16, 16, 2609, 2045, 2796, 1981, 1214, 16, 3],\n",
              " [2, 3274, 9508, 16, 16, 3, 0, 0, 0, 0, 0, 0]]"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_inputs['attention_mask']\n",
        "#일반 토큰이 자리한곳(1)과 패딩 토큰이 자리한 곳(0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4LtlhBmP5FzY",
        "outputId": "28cd3764-588b-44a1-be9a-31d24267b12c"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0],\n",
              " [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
              " [1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]]"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_inputs['token_type_ids']\n",
        "#세그먼트에 해당하는 것으로 모두0\n",
        "#버트는 보통 2개의 문서를 입력 받음 이때 token_type_ids로 구분함\n",
        "#0이면 1번 문서 1이면 2번 문서임"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DkL4RXll5HkR",
        "outputId": "a2eaf632-d270-49ed-d389-10ca22a912c1"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "faFX_lNg5JJi"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}